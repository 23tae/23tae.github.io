---
title: "[운영 체제] 04. Thread & Concurrency"
date: 2022-07-28
categories: [Computer Science, Operating System]
tags: [cs, os]
---

# Overview

### 스레드 (thread)

- 가벼운 프로세스
- CPU 활용의 기본 단위
- **스레드 ID, 프로그램 카운터, 레지스터 세트, 스택**으로 구성됨

앞에서는 프로세스가 한 개의 스레드로 실행(**싱글스레딩**)된다고 가정했음  
하지만 실제로 프로세스는 여러 개의 스레드로 실행(**멀티스레딩**)될 수 있음

![Untitled](/assets/img/cs/os/os04/Untitled.png)

[싱글스레딩과 멀티스레딩]

## 멀티스레딩의 등장 배경

아래와 같은 클라이언트-서버 시스템(웹서버 등)을 가정하면,

기존의 싱글스레딩은 서버가 클라이언트로부터 request를 수신한 뒤에 해당 request를 처리하는 동안 기존의 클라이언트로부터 수신하던 작업은 잠시 멈추게 됨.

하지만 멀티스레딩을 사용하면 request를 받고(1번), 새로 생성한 스레드에 request 처리 작업을 맡긴(2번) 후, 기존의 작업을 계속해서 할 수 있음(3번).

![Untitled](/assets/img/cs/os/os04/Untitled%201.png)

## 멀티스레딩의 이점

- **응답성(Responsiveness)**
    - 프로세스(UI 등)의 일부가 차단되는 경우에도 지속적인 실행이 가능함
- **리소스의 공유(Resource Sharing)**
    - 프로세스의 리소스를 스레드끼리 공유해서 **스레드간 협업**이 가능
    - 리소스 공유가 IPC 메커니즘(shared-memory, message-passing)보다 **용이함**.
- **경제성(Economy)**
    - 스레드 생성이 프로세스 생성보다 **경제적**임
    - thread switching이 context switching에 비해 간접비가 적음
- **확장성(Scalability)**
    - 멀티프로세스 아키텍처에서 각 스레드가 다른 프로세서에서 병렬로 처리될 수 있음

# Multicore Programming

## 멀티스레딩 in 멀티코어 시스템

- 동시성(concurrecy) 향상을 위한 멀티 코어 사용의 효율적 방법임
- 4스레드의 애플리케이션이 있을 때,
    - 싱글 코어 : 스레드들이 시간별로 배치됨 (Concurrent execution)
    
    ![Untitled](/assets/img/cs/os/os04/Untitled%202.png)
    
    - 멀티 코어 : 몇몇 스레드는 동시에 작동할 수 있음 (Parallel execution)
    
    ![Untitled](/assets/img/cs/os/os04/Untitled%203.png)
    

## 멀티코어 시스템의 문제점

- **태스크 인식(identifying tasks)**
    - 애플리케이션을 분석해서 같은 코어(separate), 다른 코어(concurrent)에서 할 작업을 나눠야 함
- **균형(balance)**
    - 분리할 파트간의 균형을 맞춰야 함
- **데이터 분리(data spliting)**
    - 데이터도 각각의 코어에서 실행되게 분리되어야 함
- **데이터 종속성(data dependency)**
    - 작업을 끝내고 데이터 동기화를 해야 함 (분리된 데이터를 기존의 형태에 맞게 합쳐주는 작업 필요)
- **테스팅**과 **디버깅**이 싱글스레드에 비해 어려움

## 병렬성(Parallelism)의 종류

- Data Parallelism

![Untitled](/assets/img/cs/os/os04/Untitled%204.png)

- Task Parallelism

![Untitled](/assets/img/cs/os/os04/Untitled%205.png)

## **암달의 법칙 (Amdahl's law)**

컴퓨터 시스템의 일부를 개선할 때 전체적으로 얼마만큼의 최대 성능 향상이 있는지 계산하는 공식

### 공식

![Untitled](/assets/img/cs/os/os04/Untitled%206.png)

- S : 연속적으로 실행되어야 하는 시스템의 비율, N : 코어의 개수

### 주요 내용

- 코어는 무조건 많을수록 좋을까?
- 실제로는 연속적으로 실행되어야 하는 시스템의 비율이 증가할수록 코어의 증가가 성능 향상에 미치는 영향은 감소함

![Untitled](/assets/img/cs/os/os04/Untitled%207.png)

# Multithreading Models

## 스레드의 종류

- **user** thread
    - kernel 윗단에 제공됨
    - kernel의 지원 없이 관리됨
- **kernel** thread
    - OS의 지원을 받으며 직접적으로 관리됨

![Untitled](/assets/img/cs/os/os04/Untitled%208.png)

## user-kernel 스레드의 관계

- **다대일 모델** (Many-to-One)
    
    ![Untitled](/assets/img/cs/os/os04/Untitled%209.png)
    
- **일대일 모델** (One-to-One)
    
    ![Untitled](/assets/img/cs/os/os04/Untitled%2010.png)
    
- **다대다 모델** (Many-to-Many)
    
    ![Untitled](/assets/img/cs/os/os04/Untitled%2011.png)
    

# Thread Libraries

개발자에게 스레드 생성, 관리에 필요한 API를 제공함

## 라이브러리 구현 방법

- user-space에서 구현
- kernel-level에서 구현

## 주요 라이브러리

- POSIX Pthread
- Windows thread
- Java thread

## Pthreads

- POSIX standard(IEEE 1003.1c)가 스레드 생성, 동기화를 위해 정의한 API를 참조함
    - 참조한 부분은 스레드 동작에 대한 명세일 뿐, 구현에 관한 내용은 아님.

## Java Threads

- Java의 프로그램 실행 기본 모델임
- 스레드 생성과 관리를 위한 풍부한 기능을 제공함

### 스레드 생성

- Thread 클래스를 **상속**
    - Thread 클래스로부터 나온 새 클래스를 생성함
    - 해당 클래스에 `public void run()` 메소드를 override
- Runnable 인터페이스를 구현
    - Runnable 인터페이스를 제공하는 새 클래스를 정의함
    - 해당 클래스에 `public void run()` 메소드를 override
- 람다 표현식(Lambda Expression) 사용
    - 새 클래스를 정의하는 대신 Runnable 람다식을 사용함
    - 람다식 : 함수를 하나의 식으로 표현한 것. 메소드의 이름을 버린 익명 함수.

### 스레드 대기 / 종료

- 부모 스레드의 **대기** : ~~wait()~~  `join`
- 스레드의 **종료** : ~~stop~~  `interrupt`

# Implicit Threading

**멀티 코어 프로세싱**이 성장함에 따라 수백, 수천 개의 스레드를 가진 애플리케이션이 등장함. 개발자가 이런 애플리케이션을 디자인하는 것은 상당히 어려움.

이런 어려움을 해결하고 concurrent하며 parellel한 애플리케이션을 더 잘 지원할 수 있는 방법은 스레드의 생성과 관리의 역할을 앱 **개발자**에게서 **컴파일러**와 **런타임 라이브러리**에게로 옮기는 것임. 다른 말로 하면 **암묵적 스레딩(implicit threading)**.

## 암묵적 스레딩의 주요 방법

- Thread Pools
- Fork & Join
- OpenMP
- Grand Central Dispatch (GCD)
- Intel Thread Building Blocks

## 스레드 풀(Thread Pools)

스레드를 풀에 **미리 생성**한 후, 작업이 들어오면 이곳에 있는 스레드가 해당 작업을 처리함

앞부분 [멀티스레딩의 등장 배경](#멀티스레딩의-등장-배경) 파트에서 스레드의 생성은 프로세스에 요청이 들어와도 기존의 작업을 이어갈 수 있는 장점이 있다고 했음. 이러한 스레드 생성은 프로세스 생성보다는 낫지만 여전히 잠재적인 문제가 있음.

### 스레드 생성의 문제점

- 스레드를 생성하는데에 시간이 소요됨. 또한 이렇게 만든 스레드가 작업이 끝나면 버려짐
- concurrent하게 동작하는 스레드의 개수에 한계치를 설정할 수 없음 → 시스템이 감당할 수 있는 범위를 넘어서면 문제가 발생할 수 있음

그 해결책으로 나온 개념이 바로 **스레드 풀**

### 스레드 풀에서의 동작 과정
![thread pools](/assets/img/cs/os/os04/thread-pools.png)
- 일정한 스레드를 시작 시에 생성하여 풀(이들이 쉬면서 작업을 기다리는 곳)에 위치시킴
- 서버가 요청을 받으면 스레드를 생성하는 대신 해당 요청을 풀에 넘겨줌. 서버는 계속해서 추가적인 요청을 기다림.
- 풀에 여유 스레드가 있다면 → 스레드를 깨워서 요청을 즉시 처리함
- 풀에 여유 스레드가 없다면 → 여유 스레드가 생길때까지 작업을 대기함
- 스레드가 작업을 완료하면 풀에 돌아와서 다른 작업을 기다림

### 스레드 풀의 장점

- 기존의 스레드로 요청을 처리하는 것이 새로운 스레드가 생성될 때까지 기다리는 것보다 빠름
- 한 시점에 존재하는 스레드의 수를 제한함. 대규모의 병렬 처리를 지원할 수 없는 시스템의 경우 이점이 특히 중요함.
- 수행할 작업을 작업의 생성 장소와 분리함으로서 작업 실행에 다양한 전략을 취할 수 있음.
    - 예를 들어, 작업이 시간 딜레이를 두고 실행되거나
    - 작업이 특정 시간에 실행되게 예약할 수 있음.

## OpenMP

병렬로 처리되기를 원하는 부분을 지정해서 병렬적으로 실행함. 컴파일러에게 지시문을 통해 지시하면 OpenMP 런타임 라이브러리가 해당 부분을 병렬 처리함.

아래 코드를  `gcc -fopenmp <filename>` 으로 컴파일해서 실행하면 병렬적으로 실행하게됨.

```c
#include <stdio.h>
#include <omp.h>

int main(int argc, char *argv[])
{
	#pragma omp parallel // compiler directive
	{
		printf("I am a parallel region.\n");
	}
	return 0;
}
```

`#pragma omp parallel` : OpenMP 지시문. 여러 스레드에서 병렬로 실행할 코드인 **병렬 영역**을 정의함.

# Ref.
<https://www.nginx.com/blog/thread-pools-boost-performance-9x/>  
<https://docs.microsoft.com/ko-kr/cpp/parallel/openmp/reference/openmp-directives?view=msvc-170>